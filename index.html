<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#000000">
    <title>AI Ultimate Pro</title>

    <!-- æ ¸å¿ƒåº« -->
    <script async src="https://docs.opencv.org/4.5.0/opencv.js" onload="onOpenCvReady();"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>
    <script src='https://unpkg.com/tesseract.js@v2.1.0/dist/tesseract.min.js'></script>

    <style>
        :root { --accent: #00d2ff; --warn: #ffd700; --track: #00ff00; --bg: #000; }
        body { margin: 0; background: var(--bg); font-family: sans-serif; color: white; height: 100dvh; display: flex; flex-direction: column; overflow: hidden; user-select: none; }
        
        .top-bar { 
            position: absolute; top: 0; left: 0; right: 0; z-index: 20;
            background: linear-gradient(to bottom, rgba(0,0,0,0.8), transparent);
            padding: 10px; padding-top: max(10px, env(safe-area-inset-top));
            display: flex; flex-direction: column; gap: 8px; pointer-events: none;
        }
        .top-bar > * { pointer-events: auto; }
        
        .row { display: flex; justify-content: space-between; align-items: center; }
        .scroll-x { overflow-x: auto; padding-bottom: 5px; display: flex; gap: 8px; scrollbar-width: none; }

        .cam-pill {
            background: rgba(50,50,50,0.8); padding: 4px 10px; border-radius: 15px; 
            font-size: 11px; border: 1px solid #555; color: #ccc; white-space: nowrap;
        }
        .cam-pill.active { background: #fff; color: #000; border-color: #fff; }

        .tool-btn {
            background: rgba(50,50,50,0.8); border: 1px solid #555; color: #ccc;
            padding: 4px 8px; border-radius: 8px; font-size: 11px; display: flex; align-items: center; gap: 4px; white-space: nowrap;
        }
        .tool-btn.active { border-color: var(--accent); color: var(--accent); background: rgba(0, 210, 255, 0.15); }

        .viewport { 
            position: relative; flex-grow: 1; background: #000; 
            display: flex; justify-content: center; align-items: center; overflow: hidden;
        }
        video { width: 100%; height: 100%; object-fit: contain; }
        canvas.overlay { position: absolute; top:0; left:0; width: 100%; height: 100%; object-fit: contain; pointer-events: none; }

        #mask {
            position: absolute; inset: 0; background: rgba(0,0,0,0.8); z-index: 50;
            display: none; justify-content: center; align-items: center; flex-direction: column;
        }
        .spinner {
            width: 30px; height: 30px; border: 3px solid #333; border-top: 3px solid var(--accent); 
            border-radius: 50%; animation: spin 1s infinite linear; margin-bottom: 10px;
        }
        @keyframes spin { 100% { transform: rotate(360deg); } }

        .controls { 
            background: linear-gradient(to top, black, transparent); 
            padding: 20px; padding-bottom: max(20px, env(safe-area-inset-bottom));
            display: flex; flex-direction: column; gap: 15px; z-index: 20;
        }

        .mode-ribbon {
            display: flex; gap: 25px; overflow-x: auto; padding: 5px 35%;
            scrollbar-width: none;
        }
        .mode-item {
            font-size: 13px; font-weight: bold; color: #666; white-space: nowrap; 
            text-transform: uppercase; transition: 0.2s;
        }
        .mode-item.active { color: var(--warn); transform: scale(1.1); text-shadow: 0 0 10px rgba(255, 215, 0, 0.5); }

        .shutter-area { display: flex; justify-content: center; align-items: center; position: relative; }
        .shutter {
            width: 70px; height: 70px; border-radius: 50%; border: 4px solid rgba(255,255,255,0.4);
            background: white; cursor: pointer; transition: 0.1s;
        }
        .shutter:active { transform: scale(0.9); }

        /* æƒæèˆ‡è­˜åˆ¥æ¡†æ¨£å¼ */
        .scan-rect { stroke: #00ff00; stroke-width: 3; fill: rgba(0,255,0,0.1); }
        .detect-rect { stroke: #00ffff; stroke-width: 2; }
        .detect-label { fill: #00ffff; font-size: 14px; font-weight: bold; }
    </style>
</head>
<body>

    <div class="top-bar">
        <div class="row">
            <div id="camList" class="scroll-x"></div>
            <div class="tool-btn" id="gestureBtn" onclick="toggleGesture()">âœ‹ æ‰‹å‹¢</div>
        </div>
        <div class="row scroll-x" style="margin-top:5px;">
             <div class="tool-btn active" id="claheBtn">é€šé€</div>
             <div class="tool-btn active" id="denoiseBtn">é™å™ª</div>
             <div class="tool-btn" id="upscaleBtn">2x AI</div>
        </div>
    </div>

    <div class="viewport">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="cOverlay" class="overlay"></canvas>
        <div id="mask">
            <div class="spinner"></div>
            <div id="maskText" style="color:#fff; font-size:14px;">Loading...</div>
        </div>
    </div>

    <div class="controls">
        <div class="mode-ribbon">
            <div class="mode-item active" onclick="setMode('PRO')">PRO</div>
            <div class="mode-item" onclick="setMode('SCAN')">æƒæ</div>
            <div class="mode-item" onclick="setMode('DETECT')">è­˜åˆ¥</div>
            <div class="mode-item" onclick="setMode('OCR')">ç¿»è­¯</div>
        </div>
        <div class="shutter-area">
            <div class="shutter" onclick="capture()"></div>
        </div>
    </div>

<script>
    const video = document.getElementById('video');
    const cOverlay = document.getElementById('cOverlay');
    const ctxOverlay = cOverlay.getContext('2d');
    const mask = document.getElementById('mask');
    const maskText = document.getElementById('maskText');
    
    let stream, videoTrack, imageCapture;
    let currentMode = 'PRO';
    let isOpenCvReady = false;
    let isProcessing = false;

    // AI Models
    let models = { coco: null, gesture: null };
    let isGestureEnabled = false;
    let lastGestureTime = 0;

    // Scan Variables
    let scanContour = null; // å­˜å„²åµæ¸¬åˆ°çš„æ–‡ä»¶è¼ªå»“

    function onOpenCvReady() { 
        isOpenCvReady = true; 
        console.log("OpenCV Ready");
    }

    async function init() {
        try {
            stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: {ideal: 1280}, height: {ideal: 720} } 
            });
            video.srcObject = stream;
            videoTrack = stream.getVideoTracks()[0];
            
            try { imageCapture = new ImageCapture(videoTrack); } catch(e){}

            // Render Cameras
            const devs = await navigator.mediaDevices.enumerateDevices();
            const cams = devs.filter(d => d.kind === 'videoinput');
            const camList = document.getElementById('camList');
            camList.innerHTML = '';
            cams.forEach((c, i) => {
                const d = document.createElement('div');
                d.className = 'cam-pill';
                d.innerText = c.label.includes('front') ? 'å‰é¡' : `é¡é ­ ${i+1}`;
                d.onclick = () => switchCam(c.deviceId);
                camList.appendChild(d);
            });

            video.onloadedmetadata = () => {
                cOverlay.width = video.videoWidth;
                cOverlay.height = video.videoHeight;
                requestAnimationFrame(renderLoop);
            };

        } catch(e) { alert("Camera Error: " + e.message); }
    }

    async function switchCam(id) {
        stream.getTracks().forEach(t => t.stop());
        stream = await navigator.mediaDevices.getUserMedia({ video: { deviceId: {exact: id}, width: {ideal: 1280} } });
        video.srcObject = stream;
        videoTrack = stream.getVideoTracks()[0];
        try { imageCapture = new ImageCapture(videoTrack); } catch(e){}
    }

    // --- æ¨¡å¼åˆ‡æ› ---
    window.setMode = async function(mode) {
        if(currentMode === mode) return;
        currentMode = mode;
        
        document.querySelectorAll('.mode-item').forEach(el => 
            el.classList.toggle('active', el.innerText === getModeName(mode)));

        // è­˜åˆ¥æ¨¡å¼ï¼šé è¼‰å…¥æ¨¡å‹
        if(mode === 'DETECT' && !models.coco) {
            showMask("è¼‰å…¥è­˜åˆ¥æ¨¡å‹...");
            try {
                models.coco = await cocoSsd.load();
            } catch(e) { alert("æ¨¡å‹è¼‰å…¥å¤±æ•—"); setMode('PRO'); }
            hideMask();
        }
    }

    function getModeName(m) {
        return { 'PRO':'PRO', 'SCAN':'æƒæ', 'DETECT':'è­˜åˆ¥', 'OCR':'ç¿»è­¯' }[m] || m;
    }

    // --- ä¸»æ¸²æŸ“è¿´åœˆ (AI é è¦½) ---
    async function renderLoop() {
        if(video.readyState === 4) {
            ctxOverlay.clearRect(0, 0, cOverlay.width, cOverlay.height);

            // 1. æ‰‹å‹¢å¿«é–€
            if(isGestureEnabled) await runGesture();

            // 2. è­˜åˆ¥æ¨¡å¼
            if(currentMode === 'DETECT' && models.coco) {
                const preds = await models.coco.detect(video);
                preds.forEach(p => {
                    const [x, y, w, h] = p.bbox;
                    ctxOverlay.strokeStyle = '#00ffff';
                    ctxOverlay.lineWidth = 2;
                    ctxOverlay.strokeRect(x, y, w, h);
                    ctxOverlay.fillStyle = '#00ffff';
                    ctxOverlay.font = '16px sans-serif';
                    ctxOverlay.fillText(`${p.class} ${Math.round(p.score*100)}%`, x, y > 10 ? y-5 : y+15);
                });
            }

            // 3. æƒææ¨¡å¼ (OpenCV é‚Šç·£åµæ¸¬)
            if(currentMode === 'SCAN' && isOpenCvReady) {
                processScanPreview();
            }
        }
        requestAnimationFrame(renderLoop);
    }

    // --- åŠŸèƒ½ï¼šæƒæé è¦½ (OpenCV) ---
    function processScanPreview() {
        try {
            // ç‚ºäº†æ•ˆèƒ½ï¼Œç¸®å°è™•ç†
            let src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            let cap = new cv.VideoCapture(video);
            cap.read(src);
            
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
            cv.Canny(gray, gray, 75, 200);

            let contours = new cv.MatVector();
            let hierarchy = new cv.Mat();
            cv.findContours(gray, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

            let maxArea = 0;
            let bestCnt = null;

            for(let i=0; i<contours.size(); ++i) {
                let cnt = contours.get(i);
                let area = cv.contourArea(cnt);
                if(area > 5000) {
                    let peri = cv.arcLength(cnt, true);
                    let approx = new cv.Mat();
                    cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
                    if(approx.rows === 4 && area > maxArea) {
                        maxArea = area;
                        if(bestCnt) bestCnt.delete();
                        bestCnt = approx; // æš«å­˜ä½†ä¸ deleteï¼Œç›´åˆ°è¿´åœˆçµæŸ
                    } else {
                        approx.delete();
                    }
                }
            }
            
            // ç¹ªè£½çµæœ
            if(bestCnt) {
                ctxOverlay.strokeStyle = '#00ff00';
                ctxOverlay.lineWidth = 4;
                ctxOverlay.beginPath();
                // è®€å–å››å€‹é»
                let pts = [];
                for(let i=0; i<4; i++) {
                    pts.push({x: bestCnt.data32S[i*2], y: bestCnt.data32S[i*2+1]});
                }
                ctxOverlay.moveTo(pts[0].x, pts[0].y);
                for(let i=1; i<4; i++) ctxOverlay.lineTo(pts[i].x, pts[i].y);
                ctxOverlay.closePath();
                ctxOverlay.stroke();
                
                // å­˜åˆ°å…¨åŸŸè®Šæ•¸ä¾›æ‹ç…§ç”¨ (é€™è£¡ç°¡åŒ–ï¼Œåƒ…å­˜æœ€å¾Œä¸€å¹€)
                scanContour = pts; 
                bestCnt.delete();
            } else {
                scanContour = null;
            }

            src.delete(); gray.delete(); contours.delete(); hierarchy.delete();
        } catch(e) {
            // é¿å… OpenCV å ±éŒ¯å¡æ­»è¿´åœˆ
            // console.log(e);
        }
    }

    // --- åŠŸèƒ½ï¼šæ‹ç…§èˆ‡åŸ·è¡Œ ---
    async function capture() {
        showMask("è™•ç†ä¸­...");
        
        try {
            // å–å¾—é«˜ç•«è³ªå½±åƒ
            let canvas = await grabFrame();
            
            if(currentMode === 'OCR') {
                await doOCR(canvas);
            } else if (currentMode === 'SCAN') {
                await doScanCrop(canvas);
            } else {
                // PRO & DETECT: å­˜åœ– (å« 2x AI é‚è¼¯)
                // è‹¥è¦å¯¦ä½œ AI æ”¾å¤§èˆ‡é™å™ªï¼Œå¯åœ¨æ­¤å‘¼å«ä¹‹å‰ç‰ˆæœ¬çš„ processImageCv
                // é€™è£¡ç°¡åŒ–ç›´æ¥è¼¸å‡º
                saveImage(canvas, currentMode);
            }
        } catch(e) { alert("Error: " + e.message); }
        
        hideMask();
    }

    // --- åŠŸèƒ½ï¼šOCR ---
    async function doOCR(canvas) {
        maskText.innerText = "è­˜åˆ¥æ–‡å­—ä¸­...";
        const res = await Tesseract.recognize(canvas, 'eng+chi_tra', {
            logger: m => { if(m.status === 'recognizing text') maskText.innerText = `OCR: ${(m.progress*100).toFixed(0)}%`; }
        });
        
        const text = res.data.text;
        if(text.trim()) {
            if(confirm(`è­˜åˆ¥çµæœ:\n${text.substring(0, 50)}...\n\nå‰å¾€ Google ç¿»è­¯?`)) {
                window.open(`https://translate.google.com/?text=${encodeURIComponent(text)}`, '_blank');
            }
        } else {
            alert("æœªåµæ¸¬åˆ°æ–‡å­—");
        }
    }

    // --- åŠŸèƒ½ï¼šæƒæè£åˆ‡ (Perspective Transform) ---
    async function doScanCrop(canvas) {
        if(!scanContour || typeof cv === 'undefined') {
            alert("æœªåµæ¸¬åˆ°æ–‡ä»¶ï¼Œè«‹å°æº–æ–‡ä»¶é‚Šç·£");
            return;
        }

        // OpenCV é€è¦–è®Šæ›
        let src = cv.imread(canvas);
        let dst = new cv.Mat();
        
        // ä¾†æºé» (éœ€è¦æ’åºï¼šå·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹) - é€™è£¡åšç°¡æ˜“æ’åº
        // å¯¦éš›æ‡‰ç”¨éœ€æ›´åš´è¬¹çš„å¹¾ä½•æ’åº
        let pts = scanContour.sort((a,b) => a.y - b.y); // å…ˆåˆ†ä¸Šä¸‹
        let top = pts.slice(0, 2).sort((a,b) => a.x - b.x); // ä¸Šæ’åˆ†å·¦å³
        let bottom = pts.slice(2, 4).sort((a,b) => a.x - b.x); // ä¸‹æ’åˆ†å·¦å³
        let sortedPts = [top[0], top[1], bottom[1], bottom[0]]; // TL, TR, BR, BL

        // ç›®æ¨™å°ºå¯¸ (A4æ¯”ä¾‹ æˆ– è‡ªå‹•è¨ˆç®—)
        let width = Math.max(
            Math.hypot(sortedPts[1].x - sortedPts[0].x, sortedPts[1].y - sortedPts[0].y),
            Math.hypot(sortedPts[2].x - sortedPts[3].x, sortedPts[2].y - sortedPts[3].y)
        );
        let height = Math.max(
            Math.hypot(sortedPts[3].x - sortedPts[0].x, sortedPts[3].y - sortedPts[0].y),
            Math.hypot(sortedPts[2].x - sortedPts[1].x, sortedPts[2].y - sortedPts[1].y)
        );

        let srcTri = cv.matFromArray(4, 1, cv.CV_32FC2, [
            sortedPts[0].x, sortedPts[0].y, sortedPts[1].x, sortedPts[1].y,
            sortedPts[2].x, sortedPts[2].y, sortedPts[3].x, sortedPts[3].y
        ]);
        let dstTri = cv.matFromArray(4, 1, cv.CV_32FC2, [0, 0, width, 0, width, height, 0, height]);
        
        let M = cv.getPerspectiveTransform(srcTri, dstTri);
        cv.warpPerspective(src, dst, M, new cv.Size(width, height));
        
        // å¢å¼·å°æ¯” (æ–‡ä»¶æ¨¡å¼)
        cv.cvtColor(dst, dst, cv.COLOR_RGBA2GRAY);
        cv.adaptiveThreshold(dst, dst, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);
        
        cv.imshow(canvas, dst); // å¯«å› Canvas
        saveImage(canvas, "Scan");

        src.delete(); dst.delete(); srcTri.delete(); dstTri.delete(); M.delete();
    }

    // --- è¼”åŠ©ï¼šæ‰‹å‹¢ ---
    async function toggleGesture() {
        if(!isGestureEnabled) {
            showMask("è¼‰å…¥æ‰‹å‹¢æ¨¡å‹...");
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm");
            models.gesture = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task" },
                runningMode: "VIDEO"
            });
            hideMask();
            isGestureEnabled = true;
            document.getElementById('gestureBtn').classList.add('active');
        } else {
            isGestureEnabled = false;
            document.getElementById('gestureBtn').classList.remove('active');
        }
    }

    async function runGesture() {
        if(!models.gesture) return;
        let now = Date.now();
        if(now - lastGestureTime < 2000) return;

        const res = models.gesture.recognizeForVideo(video, now);
        if(res.gestures.length > 0) {
            const name = res.gestures[0][0].categoryName;
            if(name === "Victory" || name === "Open_Palm") {
                lastGestureTime = now;
                showMask(`ğŸ“¸ 3ç§’å¾Œæ‹æ” (${name})`);
                setTimeout(() => { hideMask(); capture(); }, 3000);
            }
        }
    }

    // --- è¼”åŠ©å‡½å¼ ---
    async function grabFrame() {
        if(imageCapture) {
            try {
                const blob = await imageCapture.takePhoto();
                const bmp = await createImageBitmap(blob);
                const c = document.createElement('canvas');
                c.width = bmp.width; c.height = bmp.height;
                c.getContext('2d').drawImage(bmp, 0, 0);
                return c;
            } catch(e) {}
        }
        const c = document.createElement('canvas');
        c.width = video.videoWidth; c.height = video.videoHeight;
        c.getContext('2d').drawImage(video, 0, 0);
        return c;
    }

    function saveImage(canvas, prefix) {
        const a = document.createElement('a');
        a.download = `${prefix}_${Date.now()}.jpg`;
        a.href = canvas.toDataURL('image/jpeg', 0.9);
        a.click();
    }

    function showMask(text) { mask.style.display = 'flex'; maskText.innerText = text; }
    function hideMask() { mask.style.display = 'none'; }

    init();
</script>
</body>
</html>



