<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Ultimate Cam (Hybrid Engine)</title>
    <!-- ÂºïÂÖ• OpenCV.js -->
    <script async src="https://docs.opencv.org/4.5.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
    <style>
        :root { --accent: #00d2ff; --warn: #ffd700; --active: #00ff88; --bg: #000; --panel: #111; }
        body { margin: 0; background: var(--bg); font-family: -apple-system, Roboto, sans-serif; color: white; height: 100dvh; display: flex; flex-direction: column; overflow: hidden; user-select: none; }
        
        /* --- È†ÇÈÉ®Â∑•ÂÖ∑Âàó --- */
        .top-bar { 
            background: rgba(20,20,25,0.95); padding: 8px 12px; z-index: 20;
            display: flex; flex-direction: column; gap: 8px; border-bottom: 1px solid #333;
            padding-top: max(10px, env(safe-area-inset-top));
        }
        
        .row { display: flex; justify-content: space-between; align-items: center; width: 100%; gap: 8px; }
        
        select { background: #222; color: #fff; border: 1px solid #555; padding: 6px; border-radius: 6px; font-size: 12px; flex-grow: 1; max-width: 140px; }
        
        /* ÂºïÊìéÁãÄÊÖãËàáÈñãÈóú */
        .engine-status { font-size: 10px; color: #666; display: flex; align-items: center; gap: 4px; border: 1px solid #333; padding: 2px 6px; border-radius: 4px; }
        .engine-status.ready { color: var(--accent); border-color: var(--accent); }
        .dot { width: 6px; height: 6px; border-radius: 50%; background: currentColor; }

        .scroll-row { overflow-x: auto; padding-bottom: 4px; display: flex; gap: 6px; scrollbar-width: none; }
        .scroll-row::-webkit-scrollbar { display: none; }

        .toggle-btn {
            background: #222; border: 1px solid #444; color: #aaa; padding: 4px 10px; border-radius: 12px; font-size: 11px; cursor: pointer; display: flex; align-items: center; gap: 4px; white-space: nowrap; flex-shrink: 0;
        }
        .toggle-btn input { margin: 0; display: none; }
        .toggle-btn.active { border-color: var(--accent); color: var(--accent); background: rgba(0, 210, 255, 0.1); font-weight: bold; }
        
        /* ÁáàÂÖâÊéßÂà∂ */
        .light-group { display: flex; background: #222; border-radius: 8px; border: 1px solid #444; padding: 2px; }
        .light-btn { padding: 4px 8px; font-size: 14px; cursor: pointer; border-radius: 6px; border: none; background: transparent; color: #666; transition: 0.2s; }
        .light-btn.active { background: var(--warn); color: #000; }

        /* --- Ë¶ñÁ™óÂçÄÂüü --- */
        .viewport { 
            flex-grow: 1; position: relative; background: #050505; overflow: hidden;
            display: flex; justify-content: center; align-items: center; 
            touch-action: none;
        }
        video { width: 100%; height: 100%; object-fit: contain; }

        /* ÁãÄÊÖãÊåáÁ§∫ËàáÂ∞çÁÑ¶Ê°Ü */
        #status-pill {
            position: absolute; top: 15px; left: 15px;
            background: rgba(0,0,0,0.6); padding: 4px 10px; border-radius: 15px;
            font-size: 11px; color: var(--active); border: 1px solid rgba(0,255,136,0.3); pointer-events: none; z-index: 10;
        }
        .warn-mode { color: var(--warn) !important; border-color: var(--warn) !important; }

        #focus-reticle {
            position: absolute; width: 60px; height: 60px;
            border: 2px solid #fff; border-radius: 8px;
            box-shadow: 0 0 5px rgba(0,0,0,0.5);
            display: none; pointer-events: none; z-index: 30; transform: translate(-50%, -50%);
        }
        #focus-reticle.focusing { animation: focus-anim 0.5s ease-out forwards; }
        @keyframes focus-anim {
            0% { width: 80px; height: 80px; opacity: 1; border-color: #fff; }
            50% { border-color: var(--warn); }
            100% { width: 60px; height: 60px; border-color: var(--active); opacity: 0; }
        }

        #tracker-box {
            position: absolute; width: 80px; height: 80px;
            border: 2px solid var(--active); border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 255, 0, 0.5);
            display: none; pointer-events: none; transition: all 0.1s linear; z-index: 10;
        }
        #tracker-box::before { content: ''; position: absolute; top: 50%; left: 20%; right: 20%; height: 1px; background: var(--active); }
        #tracker-box::after { content: ''; position: absolute; left: 50%; top: 20%; bottom: 20%; width: 1px; background: var(--active); }

        /* --- ËôïÁêÜ‰∏≠ÈÅÆÁΩ© (HUD) --- */
        #hud {
            position: absolute; inset: 0; background: rgba(0,0,0,0.9); z-index: 50;
            display: none; justify-content: center; align-items: center; flex-direction: column; gap: 15px;
        }
        .spinner {
            width: 45px; height: 45px; border-radius: 50%;
            border: 3px solid #333; border-top: 3px solid var(--active); border-right: 3px solid var(--accent);
            animation: spin 0.8s infinite linear;
        }
        .hud-text { font-family: monospace; color: #fff; font-size: 14px; text-align: center; }
        .hud-sub { color: #888; font-size: 11px; margin-top: 5px; }

        /* --- Â∫ïÈÉ®ÊéßÂà∂ --- */
        .controls { 
            background: var(--panel); padding: 10px 15px; flex-shrink: 0; z-index: 20;
            border-top: 1px solid #333; display: grid; grid-template-columns: 1fr 70px; gap: 10px;
            padding-bottom: max(20px, env(safe-area-inset-bottom));
        }

        .sliders-col { display: flex; flex-direction: column; gap: 12px; justify-content: center; }
        .slider-row { width: 100%; display: flex; align-items: center; gap: 8px; font-size: 11px; font-weight: bold; color: #888; }
        .label { width: 40px; text-align: right; }
        .value-disp { width: 30px; text-align: right; font-family: monospace; color: #fff; }
        
        input[type=range] { flex-grow: 1; height: 4px; border-radius: 2px; -webkit-appearance: none; background: #333; }
        input[type=range]::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; border-radius: 50%; background: #ddd; box-shadow: 0 2px 5px rgba(0,0,0,0.5); }
        
        .ac-iso input { accent-color: #ff0055; }
        .ac-focus input { accent-color: var(--warn); }
        .ac-ev input { accent-color: var(--accent); }
        .ac-sharp input { accent-color: #fff; }

        .af-btn {
            background: #333; color: #fff; border: 1px solid #555; padding: 2px 0; border-radius: 4px; font-size: 10px; cursor: pointer; width: 40px; text-align: center;
        }
        .af-btn.tracking { background: var(--active); color: #000; font-weight: bold; border-color: #fff; animation: pulse 2s infinite; }
        .af-btn.manual { background: var(--warn); color: #000; font-weight: bold; }

        @keyframes pulse { 0% {box-shadow: 0 0 0 0 rgba(0, 255, 0, 0.7);} 70% {box-shadow: 0 0 0 5px rgba(0, 255, 0, 0);} 100% {box-shadow: 0 0 0 0 rgba(0, 255, 0, 0);} }

        .shutter-col { display: flex; align-items: center; justify-content: center; }
        .shutter {
            width: 68px; height: 68px; border-radius: 50%;
            border: 4px solid rgba(255,255,255,0.2);
            background: radial-gradient(circle, #fff 30%, var(--accent) 100%);
            cursor: pointer; transition: 0.1s; position: relative;
            box-shadow: 0 0 20px rgba(0, 210, 255, 0.2);
        }
        .shutter:active { transform: scale(0.92); box-shadow: 0 0 10px rgba(0, 210, 255, 0.5); }

        @keyframes spin { 100% { transform: rotate(360deg); } }
        canvas { display: none; }
    </style>
</head>
<body>

    <!-- SVG Filters (Fallback for when OpenCV is off) -->
    <svg style="width:0;height:0;position:absolute;">
        <defs>
            <filter id="smart-sharpen"><feConvolveMatrix order="3" kernelMatrix="0 -1 0 -1 5 -1 0 -1 0"/></filter>
        </defs>
    </svg>

    <div class="top-bar">
        <div class="row">
            <select id="cameraSelect"><option>Init...</option></select>
            <div id="cvStatus" class="engine-status"><div class="dot"></div> Loading CV...</div>
            <div class="light-group">
                <button class="light-btn active" id="light-off" onclick="setLightMode('off')">üö´</button>
                <button class="light-btn" id="light-flash" onclick="setLightMode('flash')">‚ö°</button>
                <button class="light-btn" id="light-torch" onclick="setLightMode('torch')">üî¶</button>
            </div>
        </div>
        
        <div class="row scroll-row">
            <label class="toggle-btn active" id="hdrBtn" onclick="toggleStyle(this)">
                <input type="checkbox" id="hdrToggle" checked> HDR
            </label>
            <label class="toggle-btn active" id="claheBtn" onclick="toggleStyle(this)">
                <input type="checkbox" id="claheToggle" checked> ‚ú® AIÈÄöÈÄè
            </label>
            <label class="toggle-btn active" id="denoiseBtn" onclick="toggleStyle(this)">
                <input type="checkbox" id="denoiseToggle" checked> üíß ÈôçÂô™
            </label>
            <label class="toggle-btn" id="upscaleBtn" onclick="toggleStyle(this)">
                <input type="checkbox" id="upscaleToggle"> 2x Zoom
            </label>
            <label class="toggle-btn" id="rawBtn" onclick="toggleStyle(this)">
                <input type="checkbox" id="rawToggle"> PNG
            </label>
        </div>
    </div>

    <div class="viewport" id="viewport">
        <video id="videoPreview" autoplay playsinline muted></video>
        <div id="status-pill">Ready</div>
        
        <!-- Â∞çÁÑ¶ UI -->
        <div id="focus-reticle"></div>
        <div id="tracker-box"></div>

        <!-- ËôïÁêÜ HUD -->
        <div id="hud">
            <div class="spinner"></div>
            <div class="hud-text">
                <div id="hud-main">Processing...</div>
                <div id="hud-sub" class="hud-sub">Initializing Pipeline</div>
            </div>
        </div>
    </div>

    <div class="controls">
        <div class="sliders-col">
            <!-- ISO -->
            <div class="slider-row ac-iso">
                <span class="label">ISO</span>
                <input type="range" id="isoSlider" min="100" max="3200" step="100" value="100">
                <span id="isoText" class="value-disp">A</span>
            </div>
            
            <!-- Focus -->
            <div class="slider-row ac-focus">
                <span class="label">Â∞çÁÑ¶</span>
                <input type="range" id="focusSlider" min="0" max="100" step="1" value="0" disabled>
                <div id="afBtn" class="af-btn" onclick="cycleFocusMode()">AF</div>
            </div>

            <!-- EV -->
            <div class="slider-row ac-ev">
                <span class="label">EV</span>
                <input type="range" id="evRange" min="-3" max="3" step="0.5" value="0">
                <span id="evText" class="value-disp">0</span>
            </div>

            <!-- Zoom -->
            <div class="slider-row ac-zoom">
                <span class="label">Zoom</span>
                <input type="range" id="zoomSlider" min="1" max="8" step="0.1" value="1" disabled>
                <span id="zoomText" class="value-disp">1x</span>
            </div>
            
             <!-- Clarity (OpenCV Sharpness) -->
            <div class="slider-row ac-sharp">
                <span class="label">Èä≥Âåñ</span>
                <input type="range" id="sharpSlider" min="0" max="100" value="30">
                <span id="sharpText" class="value-disp">30</span>
            </div>
        </div>

        <div class="shutter-col">
            <div class="shutter" onclick="captureFlow()"></div>
        </div>
    </div>

    <!-- Hidden Canvas buffers -->
    <canvas id="cBuffer"></canvas>
    <canvas id="cMotion" width="64" height="64"></canvas>

<script>
    // --- Global Vars ---
    const video = document.getElementById('videoPreview');
    const viewport = document.getElementById('viewport');
    const hud = document.getElementById('hud');
    const hudMain = document.getElementById('hud-main');
    const hudSub = document.getElementById('hud-sub');
    const cameraSelect = document.getElementById('cameraSelect');
    const cvStatus = document.getElementById('cvStatus');
    
    // Sliders & UI
    const isoSlider = document.getElementById('isoSlider');
    const focusSlider = document.getElementById('focusSlider');
    const zoomSlider = document.getElementById('zoomSlider');
    const afBtn = document.getElementById('afBtn');
    const trackerBox = document.getElementById('tracker-box');
    const focusReticle = document.getElementById('focus-reticle');
    
    let currentStream, videoTrack, imageCapture;
    let capabilities = {};
    let isOpenCvReady = false;
    let isSafeMode = false;
    let hasTorch = false;
    
    // State
    let focusModeState = 'af'; // 'af', 'mf', 'track'
    let trackingInterval;
    let prevFrameData = null;
    let softwareGain = 1.0;

    // --- Init & OpenCV ---
    function onOpenCvReady() {
        isOpenCvReady = true;
        cvStatus.innerHTML = '<div class="dot"></div> Engine Ready';
        cvStatus.classList.add('ready');
        console.log('OpenCV loaded successfully');
    }

    async function init() {
        try {
            // Permission Check
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            stream.getTracks().forEach(t => t.stop());
            
            const devices = await navigator.mediaDevices.enumerateDevices();
            const cams = devices.filter(d => d.kind === 'videoinput');
            
            cameraSelect.innerHTML = '';
            cams.forEach((d, i) => {
                const opt = document.createElement('option');
                opt.value = d.deviceId;
                opt.text = d.label || `Camera ${i}`;
                opt.dataset.index = i;
                cameraSelect.appendChild(opt);
            });

            if(cams.length > 0) {
                // Prefer back camera (usually last index)
                const lastIdx = cams.length - 1;
                cameraSelect.selectedIndex = lastIdx;
                switchCamera(cams[lastIdx].deviceId, lastIdx);
            }
            cameraSelect.onchange = e => {
                const idx = parseInt(e.target.selectedOptions[0].dataset.index);
                switchCamera(e.target.value, idx);
            };
            
            viewport.addEventListener('click', triggerTapFocus);

        } catch(e) { 
            alert("Ë´ãÂÖÅË®±Áõ∏Ê©üÊ¨äÈôê: " + e.message); 
        }
    }

    // --- Camera Control ---
    async function switchCamera(id, index) {
        setLightMode('off');
        stopTracking();
        
        if(currentStream) currentStream.getTracks().forEach(t => t.stop());
        document.getElementById('status-pill').innerText = "Switching...";
        isSafeMode = false;

        // Configuration Strategy: Try 4K, Fallback to Safe Mode (VGA)
        try {
            if (index === 2) { // Usually front/wide cam, force safe mode
                await launch({ video: { deviceId: { exact: id }, width: { ideal: 640 }, height: { ideal: 480 } } }, "Wide/VGA");
                isSafeMode = true; 
            } else {
                await launch({ video: { deviceId: { exact: id }, width: { ideal: 4096 }, height: { ideal: 4096 }, aspectRatio: 1.333 } }, "4K UHD");
            }
        } catch(e) {
            console.log("High-res failed, falling back...");
            try {
                await launch({ video: { deviceId: { exact: id }, width: { ideal: 640 }, height: { ideal: 480 } } }, "SafeMode");
                isSafeMode = true; 
            } catch(e2) {
                alert("ÂïüÂãïÁõ∏Ê©üÂ§±Êïó");
            }
        }
    }

    async function launch(constraints, label) {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        currentStream = stream;
        video.srcObject = stream;
        videoTrack = stream.getVideoTracks()[0];
        
        if(window.ImageCapture) {
            try { imageCapture = new ImageCapture(videoTrack); } catch(e){}
        }

        // Get Capabilities
        capabilities = videoTrack.getCapabilities ? videoTrack.getCapabilities() : {};
        
        // Setup Zoom
        if(capabilities.zoom) {
            zoomSlider.disabled = false;
            zoomSlider.min = capabilities.zoom.min;
            zoomSlider.max = Math.min(capabilities.zoom.max, 8); // Cap at 8x
            zoomSlider.value = 1;
        } else { zoomSlider.disabled = true; }

        // Setup ISO
        const hasIso = !!capabilities.iso;
        isoSlider.min = hasIso ? capabilities.iso.min : 100;
        isoSlider.max = hasIso ? capabilities.iso.max : 3200;
        isoSlider.value = isoSlider.min;
        document.getElementById('isoText').innerText = "A";

        // Setup Torch
        hasTorch = !!capabilities.torch;
        document.getElementById('light-torch').disabled = !hasTorch;

        // Reset UI
        resetFocusUI();
        document.getElementById('status-pill').innerText = label;
        if(isSafeMode) document.getElementById('status-pill').classList.add("warn-mode");
        else document.getElementById('status-pill').classList.remove("warn-mode");
    }

    // --- Interaction Logic (Focus, Zoom, ISO) ---
    
    // Zoom
    zoomSlider.oninput = function() {
        document.getElementById('zoomText').innerText = parseFloat(this.value).toFixed(1) + "x";
        if(videoTrack) videoTrack.applyConstraints({advanced:[{zoom:this.value}]}).catch(()=>{});
    };

    // ISO (Hybrid Hardware/Software)
    isoSlider.oninput = function() {
        const val = parseInt(this.value);
        document.getElementById('isoText').innerText = val;
        // Software simulation brightness
        softwareGain = 1.0 + ((val - 100) / 1000);
        video.style.filter = `brightness(${softwareGain})`;
        // Hardware apply
        if(capabilities.iso) videoTrack.applyConstraints({ advanced: [{ iso: val }] }).catch(()=>{});
    };

    // EV
    document.getElementById('evRange').oninput = function() { 
        document.getElementById('evText').innerText = this.value;
        if(capabilities.exposureCompensation) 
            videoTrack.applyConstraints({advanced:[{exposureCompensation:parseFloat(this.value)}]}).catch(()=>{});
    };
    
    // Sharpness UI Update
    document.getElementById('sharpSlider').oninput = function() {
        document.getElementById('sharpText').innerText = this.value;
    };

    // Light
    window.setLightMode = async function(mode) {
        if(!videoTrack) return;
        document.querySelectorAll('.light-btn').forEach(b => b.classList.remove('active'));
        document.getElementById(`light-${mode}`).classList.add('active');
        try {
            if (mode === 'torch') await videoTrack.applyConstraints({ advanced: [{ torch: true }] });
            else if (hasTorch) await videoTrack.applyConstraints({ advanced: [{ torch: false }] });
        } catch(e) {}
        window.currentLightMode = mode;
    }

    // --- Focus Logic (The "Brain") ---

    async function triggerTapFocus(e) {
        if (!videoTrack) return;
        if (focusModeState === 'track') stopTracking();
        resetFocusUI();

        // Visual
        const rect = viewport.getBoundingClientRect();
        focusReticle.style.left = `${e.clientX - rect.left}px`;
        focusReticle.style.top = `${e.clientY - rect.top}px`;
        focusReticle.style.display = 'block';
        focusReticle.classList.remove('focusing');
        void focusReticle.offsetWidth; 
        focusReticle.classList.add('focusing');

        // Hardware Command
        try {
            await videoTrack.applyConstraints({ advanced: [{ focusMode: 'auto' }] });
        } catch(err) {
            try { await videoTrack.applyConstraints({ advanced: [{ focusMode: 'continuous' }] }); } catch(e) {}
        }
    }

    function cycleFocusMode() {
        if(focusModeState === 'af') {
            // Switch to Manual
            if(capabilities.focusMode && capabilities.focusMode.includes('manual')) {
                focusModeState = 'mf';
                afBtn.innerText = "MF";
                afBtn.className = "af-btn manual";
                focusSlider.disabled = false;
                videoTrack.applyConstraints({ advanced: [{ focusMode: 'manual' }] });
            } else {
                startTrackingMode(); // Skip MF if not supported
            }
        } else if(focusModeState === 'mf') {
            // Switch to Tracking
            startTrackingMode();
        } else {
            // Back to AF
            resetFocusUI();
            videoTrack.applyConstraints({ advanced: [{ focusMode: 'continuous' }] });
        }
    }

    focusSlider.oninput = function() {
        if(focusModeState === 'mf') {
            videoTrack.applyConstraints({ advanced: [{ focusDistance: this.value / 100 }] });
        }
    }

    function resetFocusUI() {
        stopTracking();
        focusModeState = 'af';
        afBtn.innerText = "AF";
        afBtn.className = "af-btn";
        focusSlider.disabled = true;
    }

    function startTrackingMode() {
        focusModeState = 'track';
        afBtn.innerText = "üéØ";
        afBtn.className = "af-btn tracking";
        focusSlider.disabled = true;
        trackerBox.style.display = 'block';
        
        // Simple Motion Detection Tracking Logic
        if(trackingInterval) clearInterval(trackingInterval);
        const cvs = document.getElementById('cMotion');
        const ctx = cvs.getContext('2d');
        prevFrameData = null;

        trackingInterval = setInterval(() => {
            if(video.readyState !== 4) return;
            ctx.drawImage(video, 0, 0, 64, 64);
            const frame = ctx.getImageData(0, 0, 64, 64);
            const data = frame.data;

            if(prevFrameData) {
                let avgX = 0, avgY = 0, count = 0;
                for(let i=0; i<data.length; i+=16) { 
                    const diff = Math.abs(data[i] - prevFrameData[i]) + Math.abs(data[i+1] - prevFrameData[i+1]) + Math.abs(data[i+2] - prevFrameData[i+2]);
                    if(diff > 30) { 
                        const idx = i / 4;
                        avgX += (idx % 64); avgY += Math.floor(idx / 64); count++;
                    }
                }
                if(count > 5) { 
                    const cx = (avgX / count) / 64 * 100;
                    const cy = (avgY / count) / 64 * 100;
                    trackerBox.style.left = `calc(${cx}% - 40px)`;
                    trackerBox.style.top = `calc(${cy}% - 40px)`;
                    trackerBox.style.borderColor = "#00ff88"; 
                } else {
                    trackerBox.style.borderColor = "#555";
                }
            }
            prevFrameData = data;
        }, 100);
    }

    function stopTracking() {
        if(trackingInterval) clearInterval(trackingInterval);
        trackerBox.style.display = 'none';
        prevFrameData = null;
    }

    // --- Capture & Processing Pipeline (The Core Integration) ---

    async function captureFlow() {
        hud.style.display = 'flex';
        hudMain.innerText = "Capturing...";
        hudSub.innerText = "Acquiring sensor data";

        const isHdr = document.getElementById('hdrToggle').checked;
        const useOpenCV = isOpenCvReady;

        try {
            let baseCanvas;

            // Step 1: Acquisition (HDR or Single)
            if(isHdr) {
                // HDR Sequence
                const frames = [];
                // Capture -1, 0, +1 EV (Simulated or Real)
                const evSteps = [-1, 0, 1];
                for(let i=0; i<evSteps.length; i++) {
                    hudSub.innerText = `HDR Sequence ${i+1}/3`;
                    // Adjust EV
                    if(capabilities.exposureCompensation) 
                        await videoTrack.applyConstraints({advanced:[{exposureCompensation: evSteps[i]}]});
                    else 
                        await new Promise(r => setTimeout(r, 100)); // Wait for auto-exposure if hardware EV not supported
                    
                    frames.push(await grabFrame());
                }
                // Restore EV
                if(capabilities.exposureCompensation) await videoTrack.applyConstraints({advanced:[{exposureCompensation: 0}]});
                
                hudMain.innerText = "Merging...";
                baseCanvas = mergeHDR(frames);
            } else {
                // Single Shot
                const opts = (window.currentLightMode === 'flash') ? {fillLightMode: 'flash'} : {};
                baseCanvas = await grabFrame(true, opts);
            }

            // Step 2: Processing (OpenCV or Canvas)
            if (useOpenCV) {
                await processWithOpenCV(baseCanvas);
            } else {
                await processWithCanvas(baseCanvas);
            }

        } catch(e) {
            console.error(e);
            alert("Capture Error: " + e.message);
            hud.style.display = 'none';
        }
    }

    async function grabFrame(usePhotoAPI = false, opts = {}) {
        if(usePhotoAPI && imageCapture) {
            try {
                const blob = await imageCapture.takePhoto(opts);
                const bmp = await createImageBitmap(blob);
                const c = document.createElement('canvas');
                c.width = bmp.width; c.height = bmp.height;
                c.getContext('2d').drawImage(bmp, 0, 0);
                return c;
            } catch(e) { console.warn("Photo API failed, fallback to video grab"); }
        }
        const c = document.createElement('canvas');
        c.width = video.videoWidth; c.height = video.videoHeight;
        c.getContext('2d').drawImage(video, 0, 0);
        return c;
    }

    function mergeHDR(frames) {
        const base = frames[1]; // Middle exposure
        const w = base.width; const h = base.height;
        const c = document.createElement('canvas');
        c.width = w; c.height = h;
        const ctx = c.getContext('2d');
        
        // Simple Exposure Fusion
        ctx.drawImage(frames[1], 0, 0); // Base
        
        ctx.globalCompositeOperation = 'darken';
        ctx.globalAlpha = 0.5;
        ctx.drawImage(frames[0], 0, 0); // Underexposed (Recover highlights)
        
        ctx.globalCompositeOperation = 'lighten';
        ctx.globalAlpha = 0.5;
        ctx.drawImage(frames[2], 0, 0); // Overexposed (Recover shadows)
        
        ctx.globalCompositeOperation = 'source-over';
        ctx.globalAlpha = 1.0;
        return c;
    }

    // --- Processing Branch A: OpenCV (High Quality) ---
    async function processWithOpenCV(canvas) {
        hudMain.innerText = "AI Processing...";
        
        // Wait a tick to let UI update
        await new Promise(r => setTimeout(r, 50));

        try {
            const src = cv.imread(canvas);
            const dst = new cv.Mat();
            const lab = new cv.Mat();
            const labPlanes = new cv.MatVector();

            // 1. Convert to Lab color space (Separate Luminance)
            cv.cvtColor(src, lab, cv.COLOR_RGBA2RGB);
            cv.cvtColor(lab, lab, cv.COLOR_RGB2Lab);
            cv.split(lab, labPlanes);
            const L = labPlanes.get(0);

            // 2. Denoise (Bilateral Filter)
            if(document.getElementById('denoiseToggle').checked) {
                hudSub.innerText = "AI Bilateral Denoising";
                const tempL = new cv.Mat();
                // d=5, sigmaColor=75, sigmaSpace=75
                cv.bilateralFilter(L, tempL, 5, 75, 75, cv.BORDER_DEFAULT);
                tempL.copyTo(L);
                tempL.delete();
            }

            // 3. CLAHE (Contrast Limited Adaptive Histogram Equalization)
            if(document.getElementById('claheToggle').checked) {
                hudSub.innerText = "CLAHE Contrast Enhance";
                const clahe = new cv.CLAHE(2.0, new cv.Size(8, 8));
                clahe.apply(L, L);
                clahe.delete();
            }

            // 4. Sharpness (Unsharp Mask)
            const sharpVal = parseInt(document.getElementById('sharpSlider').value);
            if(sharpVal > 0) {
                hudSub.innerText = `Sharpening (Level ${sharpVal})`;
                const blurred = new cv.Mat();
                cv.GaussianBlur(L, blurred, new cv.Size(0, 0), 3);
                const amount = sharpVal / 40; 
                cv.addWeighted(L, 1 + amount, blurred, -amount, 0, L);
                blurred.delete();
            }

            // Merge back
            labPlanes.set(0, L);
            cv.merge(labPlanes, lab);
            cv.cvtColor(lab, dst, cv.COLOR_Lab2RGB);

            // Output to canvas
            cv.imshow(canvas, dst);

            // Clean up
            src.delete(); dst.delete(); lab.delete(); L.delete(); labPlanes.delete();

            await finalize(canvas);

        } catch(e) {
            console.error("OpenCV Failed", e);
            // Fallback
            processWithCanvas(canvas);
        }
    }

    // --- Processing Branch B: Canvas API (Fast/Fallback) ---
    async function processWithCanvas(canvas) {
        hudMain.innerText = "Applying Filters...";
        hudSub.innerText = "Native Canvas API";
        
        const ctx = canvas.getContext('2d');
        const temp = document.createElement('canvas');
        temp.width = canvas.width; temp.height = canvas.height;
        temp.getContext('2d').drawImage(canvas, 0, 0);

        // Filter string construction
        let filters = [];
        
        // Software ISO Brightness check
        if(softwareGain > 1.0) filters.push(`brightness(${softwareGain})`);
        
        // Simple Sharpen (SVG)
        const sharpVal = parseInt(document.getElementById('sharpSlider').value);
        if(sharpVal > 10) filters.push('url(#smart-sharpen)'); // Use the SVG filter defined in HTML

        // Contrast bump for "AI Look" fallback
        if(document.getElementById('claheToggle').checked) filters.push('contrast(1.1) saturate(1.1)');

        if(filters.length > 0) {
            ctx.filter = filters.join(' ');
            ctx.clearRect(0,0,canvas.width, canvas.height);
            ctx.drawImage(temp, 0, 0);
            ctx.filter = 'none';
        }

        await finalize(canvas);
    }

    async function finalize(canvas) {
        hudMain.innerText = "Saving...";
        
        // Upscale?
        if(document.getElementById('upscaleToggle').checked && canvas.width * canvas.height < 25000000) {
            hudSub.innerText = "2x Super Resolution";
            const big = document.createElement('canvas');
            big.width = canvas.width * 2; big.height = canvas.height * 2;
            const bCtx = big.getContext('2d');
            bCtx.imageSmoothingEnabled = true;
            bCtx.imageSmoothingQuality = 'high';
            bCtx.drawImage(canvas, 0, 0, big.width, big.height);
            canvas = big;
        }

        const isPng = document.getElementById('rawToggle').checked;
        const link = document.createElement('a');
        link.download = `IMG_${Date.now()}_${isOpenCvReady ? 'CV' : 'STD'}.${isPng ? 'png' : 'jpg'}`;
        link.href = canvas.toDataURL(isPng ? 'image/png' : 'image/jpeg', 0.92);
        link.click();
        
        hud.style.display = 'none';
    }

    // UI Utilities
    window.toggleStyle = function(el) {
        const chk = el.querySelector('input');
        chk.checked = !chk.checked;
        el.classList.toggle('active', chk.checked);
    }
    
    // Auto-Init
    init();

</script>
</body>
</html>


