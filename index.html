<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Computational Cam (OpenCV)</title>
    <!-- å¼•å…¥ OpenCV.js (é›»è…¦è¦–è¦ºåº«) -->
    <script async src="https://docs.opencv.org/4.5.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
    <style>
        body { margin: 0; background: #000; font-family: -apple-system, Roboto, sans-serif; color: white; height: 100dvh; display: flex; flex-direction: column; overflow: hidden; }
        
        .top-bar { 
            background: rgba(20,20,25,0.95); padding: 8px 12px; z-index: 20;
            display: flex; flex-direction: column; gap: 8px; border-bottom: 1px solid #333;
            padding-top: max(10px, env(safe-area-inset-top));
        }
        
        .row { display: flex; justify-content: space-between; align-items: center; width: 100%; gap: 8px; }
        
        select { background: #222; color: #fff; border: 1px solid #555; padding: 6px; border-radius: 6px; font-size: 13px; flex-grow: 1; max-width: 120px; }
        
        /* å¼•æ“ç‹€æ…‹ç‡ˆ */
        .engine-status {
            font-size: 10px; color: #555; padding: 2px 6px; border: 1px solid #333; border-radius: 4px; display: flex; align-items: center; gap: 4px;
        }
        .engine-status.ready { color: #00ff88; border-color: #00ff88; }
        .dot { width: 6px; height: 6px; border-radius: 50%; background: currentColor; }

        .feature-toggle {
            display: flex; align-items: center; gap: 4px; font-size: 11px; color: #aaa;
            background: #222; padding: 4px 8px; border-radius: 12px; border: 1px solid #444; cursor: pointer;
        }
        .feature-toggle input:checked + span { color: #00d2ff; font-weight: bold; text-shadow: 0 0 5px rgba(0, 210, 255, 0.5); }

        .viewport { 
            flex-grow: 1; position: relative; background: #111; overflow: hidden;
            display: flex; justify-content: center; align-items: center; 
        }
        video { width: 100%; height: 100%; object-fit: contain; }

        /* è™•ç†é€²åº¦ HUD */
        #cv-hud {
            position: absolute; inset: 0; background: rgba(0,0,0,0.85); z-index: 50;
            display: none; justify-content: center; align-items: center; flex-direction: column; gap: 15px;
        }
        .cv-spinner {
            width: 50px; height: 50px; border-radius: 50%;
            border: 4px solid #333; border-top: 4px solid #00ff88; border-right: 4px solid #00d2ff;
            animation: spin 1s infinite linear;
        }
        .cv-text { font-family: monospace; color: #fff; font-size: 14px; text-align: center; }
        .cv-sub { color: #888; font-size: 11px; margin-top: 5px; }

        /* åº•éƒ¨ */
        .controls { 
            background: #111; padding: 15px 20px; flex-shrink: 0; z-index: 20;
            border-top: 1px solid #333; display: flex; flex-direction: column; gap: 15px; align-items: center;
            padding-bottom: max(20px, env(safe-area-inset-bottom));
        }

        .slider-row { width: 100%; display: flex; align-items: center; gap: 10px; font-size: 12px; font-weight: bold; color: #aaa; }
        .label { width: 50px; text-align: right; }
        input[type=range] { flex-grow: 1; height: 4px; border-radius: 2px; -webkit-appearance: none; background: #444; }
        input[type=range]::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; border-radius: 50%; background: #fff; }
        
        .ac-clarity input { accent-color: #00d2ff; }
        .ac-zoom input { accent-color: #00ff88; }

        .shutter {
            width: 72px; height: 72px; border-radius: 50%;
            border: 4px solid rgba(255,255,255,0.3);
            background: radial-gradient(circle, #fff 30%, #00d2ff 100%);
            cursor: pointer; transition: 0.1s; position: relative;
            box-shadow: 0 0 20px rgba(0, 210, 255, 0.3);
        }
        .shutter:active { transform: scale(0.95); }

        @keyframes spin { 100% { transform: rotate(360deg); } }
        canvas { display: none; }
    </style>
</head>
<body>

    <div class="top-bar">
        <div class="row">
            <select id="cameraSelect"><option>Loading...</option></select>
            <div id="cvStatus" class="engine-status"><div class="dot"></div> Engine Init...</div>
        </div>
        <div class="row">
            <label class="feature-toggle">
                <input type="checkbox" id="claheToggle" checked>
                <span>âœ¨ æ™ºæ…§é€šé€ (CLAHE)</span>
            </label>
            <label class="feature-toggle">
                <input type="checkbox" id="denoiseToggle" checked>
                <span>ğŸ’§ é›™é‚Šé™å™ª</span>
            </label>
        </div>
    </div>

    <div class="viewport">
        <video id="videoPreview" autoplay playsinline muted></video>
        
        <div id="cv-hud">
            <div class="cv-spinner"></div>
            <div class="cv-text">
                <div id="cv-step">Processing...</div>
                <div id="cv-detail" class="cv-sub">OpenCV Algorithm</div>
            </div>
        </div>
    </div>

    <div class="controls">
        <div class="slider-row ac-clarity">
            <span class="label">æ¸…æ™°åº¦</span>
            <input type="range" id="sharpnessSlider" min="0" max="100" value="50">
        </div>
        <div class="slider-row ac-zoom">
            <span class="label">Zoom</span>
            <input type="range" id="zoomSlider" min="1" max="8" step="0.1" value="1" disabled>
        </div>
        <div class="shutter" onclick="capture()"></div>
    </div>

    <canvas id="canvas"></canvas>

<script>
    const video = document.getElementById('videoPreview');
    const cvStatus = document.getElementById('cvStatus');
    const hud = document.getElementById('cv-hud');
    const cvStep = document.getElementById('cv-step');
    const cvDetail = document.getElementById('cv-detail');
    const cameraSelect = document.getElementById('cameraSelect');
    
    let currentStream, videoTrack, imageCapture;
    let isOpenCvReady = false;

    // OpenCV è¼‰å…¥å›èª¿
    function onOpenCvReady() {
        isOpenCvReady = true;
        cvStatus.innerHTML = '<div class="dot"></div> CV Engine Ready';
        cvStatus.classList.add('ready');
        console.log('OpenCV.js is ready');
    }

    async function init() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            stream.getTracks().forEach(t => t.stop());
            
            const devices = await navigator.mediaDevices.enumerateDevices();
            const cams = devices.filter(d => d.kind === 'videoinput');
            
            cameraSelect.innerHTML = '';
            cams.forEach((d, i) => {
                const opt = document.createElement('option');
                opt.value = d.deviceId;
                opt.text = d.label || `Camera ${i}`;
                cameraSelect.appendChild(opt);
            });

            if(cams.length > 0) {
                const lastIdx = cams.length - 1;
                cameraSelect.selectedIndex = lastIdx;
                switchCamera(cams[lastIdx].deviceId, lastIdx);
            }
            cameraSelect.onchange = e => {
                const idx = e.target.selectedIndex;
                switchCamera(e.target.value, idx);
            };
        } catch(e) { alert("è«‹å…è¨±ç›¸æ©Ÿæ¬Šé™"); }
    }

    async function switchCamera(id, index) {
        if(currentStream) currentStream.getTracks().forEach(t => t.stop());
        try {
            // æ··åˆç­–ç•¥: Camera 2 ç”¨ VGA, å…¶ä»–ç”¨ 4K
            const constraints = (index === 2) 
                ? { video: { deviceId: { exact: id }, width: { ideal: 640 }, height: { ideal: 480 } } }
                : { video: { deviceId: { exact: id }, width: { ideal: 4096 }, height: { ideal: 4096 }, aspectRatio: 1.333 } };
            
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            currentStream = stream;
            video.srcObject = stream;
            videoTrack = stream.getVideoTracks()[0];
            
            if(window.ImageCapture) try{ imageCapture = new ImageCapture(videoTrack); }catch(e){}

            const caps = videoTrack.getCapabilities ? videoTrack.getCapabilities() : {};
            const zs = document.getElementById('zoomSlider');
            if(caps.zoom) {
                zs.disabled = false;
                zs.min = caps.zoom.min;
                zs.max = Math.min(caps.zoom.max, 8);
                zs.value = 1;
                zs.oninput = function() { videoTrack.applyConstraints({advanced:[{zoom:this.value}]}); }
            } else { zs.disabled = true; }

        } catch(e) { alert("å•Ÿå‹•å¤±æ•—"); }
    }

    async function capture() {
        if (!isOpenCvReady) {
            alert("OpenCV å¼•æ“å°šæœªè¼‰å…¥å®Œæˆï¼Œè«‹ç¨å€™...");
            return;
        }

        hud.style.display = 'flex';
        cvStep.innerText = "Capturing...";
        cvDetail.innerText = "Accessing hardware sensor";

        try {
            // 1. ç²å–åŸåœ– (High Quality)
            let bmp;
            if(imageCapture) {
                try {
                    const blob = await imageCapture.takePhoto();
                    bmp = await createImageBitmap(blob);
                } catch(e) { bmp = await grabFrame(); }
            } else {
                bmp = await grabFrame();
            }

            // 2. è½‰ç¹ªåˆ° Canvas
            const canvas = document.getElementById('canvas');
            canvas.width = bmp.width;
            canvas.height = bmp.height;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(bmp, 0, 0);

            // 3. é€²å…¥ OpenCV è™•ç†æµç¨‹
            // çµ¦ UI ä¸€é»æ™‚é–“åˆ·æ–°
            setTimeout(() => processWithOpenCV(canvas), 100);

        } catch(e) {
            alert("Error: " + e.message);
            hud.style.display = 'none';
        }
    }

    async function grabFrame() {
        const c = document.createElement('canvas');
        c.width = video.videoWidth; c.height = video.videoHeight;
        c.getContext('2d').drawImage(video, 0, 0);
        return c;
    }

    // â˜…â˜…â˜… OpenCV æ¼”ç®—æ³•æ ¸å¿ƒ â˜…â˜…â˜…
    function processWithOpenCV(canvas) {
        try {
            const src = cv.imread(canvas);
            const dst = new cv.Mat();
            
            const isClahe = document.getElementById('claheToggle').checked;
            const isDenoise = document.getElementById('denoiseToggle').checked;
            const sharpLevel = parseInt(document.getElementById('sharpnessSlider').value);

            // --- æ­¥é©Ÿ 1: è‰²å½©ç©ºé–“è½‰æ› (RGB -> Lab) ---
            // æˆ‘å€‘åªè™•ç† L (äº®åº¦) é€šé“ï¼Œé€™æ¨£å¯ä»¥é¿å…é¡è‰²å¤±çœŸ
            cvStep.innerText = "Color Space Transform";
            cvDetail.innerText = "RGB to Lab conversion";
            
            const lab = new cv.Mat();
            cv.cvtColor(src, lab, cv.COLOR_RGBA2RGB); // å…ˆè½‰ RGB
            cv.cvtColor(lab, lab, cv.COLOR_RGB2Lab);
            
            const labPlanes = new cv.MatVector();
            cv.split(lab, labPlanes); // åˆ†é›¢é€šé“: L, a, b
            const L = labPlanes.get(0);

            // --- æ­¥é©Ÿ 2: é›™é‚Šæ¿¾æ³¢ (Bilateral Filter) ---
            // é€™æ˜¯ã€Œç¾è‚Œã€æ¼”ç®—æ³•ï¼šå¹³æ»‘è¡¨é¢ä½†ä¿ç•™é‚Šç·£
            if (isDenoise) {
                cvStep.innerText = "AI Denoising";
                cvDetail.innerText = "Bilateral Filter (Edge-Preserving)";
                const tempL = new cv.Mat();
                // d=5, sigmaColor=75, sigmaSpace=75 (æ¨™æº–åƒæ•¸)
                cv.bilateralFilter(L, tempL, 5, 75, 75, cv.BORDER_DEFAULT);
                tempL.copyTo(L);
                tempL.delete();
            }

            // --- æ­¥é©Ÿ 3: CLAHE (è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡åŒ–) ---
            // å¢å¼·å±€éƒ¨å°æ¯”åº¦ï¼Œå»é™¤éœ§æ„Ÿ
            if (isClahe) {
                cvStep.innerText = "Enhancing Contrast";
                cvDetail.innerText = "CLAHE Algorithm";
                // clipLimit=2.0, tileGridSize=(8,8)
                const clahe = new cv.CLAHE(2.0, new cv.Size(8, 8));
                clahe.apply(L, L);
                clahe.delete();
            }

            // --- æ­¥é©Ÿ 4: Unsharp Mask (éŠ³åŒ–) ---
            // å…¬å¼: Sharp = Original + Amount * (Original - Blurred)
            if (sharpLevel > 0) {
                cvStep.innerText = "Applying Sharpness";
                cvDetail.innerText = `Unsharp Mask (Level ${sharpLevel})`;
                
                const blurred = new cv.Mat();
                const kSize = new cv.Size(0, 0); // è‡ªå‹•è¨ˆç®—
                const sigma = 3; 
                cv.GaussianBlur(L, blurred, kSize, sigma);
                
                // æ¬Šé‡è¨ˆç®—: åŸåœ– 1.5å€, æ¨¡ç³Šåœ– -0.5å€ (æ•¸å€¼ä¾æ»‘æ¡¿èª¿æ•´)
                const amount = sharpLevel / 50; // 0 ~ 2.0
                cv.addWeighted(L, 1 + amount, blurred, -amount, 0, L);
                blurred.delete();
            }

            // --- æ­¥é©Ÿ 5: åˆä½µèˆ‡è¼¸å‡º ---
            cvStep.innerText = "Finalizing";
            labPlanes.set(0, L); // æŠŠè™•ç†å¥½çš„ L æ”¾å›å»
            cv.merge(labPlanes, lab);
            
            cv.cvtColor(lab, dst, cv.COLOR_Lab2RGB); // è½‰å› RGB
            
            cv.imshow(canvas, dst); // ç•«å› Canvas

            // æ¸…ç†è¨˜æ†¶é«” (é‡è¦ï¼OpenCVåœ¨Webä¸Šå¾ˆå®¹æ˜“çˆ†è¨˜æ†¶é«”)
            src.delete(); dst.delete(); lab.delete(); L.delete(); labPlanes.delete();

            save(canvas);

        } catch(err) {
            console.error(err);
            alert("æ¼”ç®—æ³•è™•ç†éŒ¯èª¤");
            hud.style.display = 'none';
        }
    }

    function save(canvas) {
        const link = document.createElement('a');
        link.download = `AI_CV_${Date.now()}.jpg`;
        link.href = canvas.toDataURL('image/jpeg', 0.95);
        link.click();
        hud.style.display = 'none';
    }

    init();
</script>
</body>
</html>

