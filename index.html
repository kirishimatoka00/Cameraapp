<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    
    <!-- PWA -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="theme-color" content="#000000">

    <title>AI Ultimate Cam</title>

    <!-- æ ¸å¿ƒåº« -->
    <script async src="https://docs.opencv.org/4.5.0/opencv.js" onload="onOpenCvReady();"></script>
    <!-- TensorFlow.js (ç”¨æ–¼ç‰©ä»¶åµæ¸¬) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <!-- MediaPipe (ç”¨æ–¼äººåƒåˆ†å‰²èˆ‡æ‰‹å‹¢) -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js" crossorigin="anonymous"></script>
    <!-- Tesseract.js (ç”¨æ–¼ OCR) -->
    <script src='https://unpkg.com/tesseract.js@v2.1.0/dist/tesseract.min.js'></script>

    <style>
        :root { --accent: #00d2ff; --warn: #ffd700; --track: #00ff00; --bg: #000; }
        body { margin: 0; background: var(--bg); color: white; height: 100dvh; display: flex; flex-direction: column; overflow: hidden; user-select: none; font-family: sans-serif; }
        
        /* ç•«å¸ƒå †ç–Š */
        .viewport { position: relative; flex-grow: 1; background: #000; overflow: hidden; display: flex; justify-content: center; align-items: center; }
        video { position: absolute; width: 100%; height: 100%; object-fit: cover; display: none; } /* éš±è—åŸåœ–ï¼Œçµ±ä¸€ç”¨ Canvas ç¹ªè£½ */
        canvas { position: absolute; width: 100%; height: 100%; object-fit: cover; }
        #cOutput { z-index: 10; } /* ä¸»è¦é¡¯ç¤ºå±¤ */
        #cOverlay { z-index: 20; pointer-events: none; } /* UI ç¹ªåœ–å±¤ (æ¡†ç·šç­‰) */

        /* é ‚éƒ¨åˆ— */
        .top-bar { 
            position: absolute; top: 0; left: 0; right: 0; z-index: 30;
            background: linear-gradient(to bottom, rgba(0,0,0,0.8), transparent);
            padding: 10px 15px; padding-top: max(10px, env(safe-area-inset-top));
            display: flex; justify-content: space-between; align-items: flex-start;
        }
        .status-badge { font-size: 10px; padding: 2px 6px; border-radius: 4px; background: rgba(0,0,0,0.5); border: 1px solid #555; color: #aaa; }
        .status-badge.active { border-color: var(--accent); color: var(--accent); }

        /* å³å´åŠŸèƒ½é–‹é—œ */
        .side-tools { display: flex; flex-direction: column; gap: 10px; align-items: flex-end; }
        .tool-btn {
            width: 36px; height: 36px; border-radius: 50%; background: rgba(30,30,30,0.6);
            border: 1px solid rgba(255,255,255,0.2); color: #fff; display: flex; justify-content: center; align-items: center;
            font-size: 16px; cursor: pointer; backdrop-filter: blur(4px); transition: 0.2s;
        }
        .tool-btn.active { background: var(--accent); color: #000; border-color: #fff; box-shadow: 0 0 10px var(--accent); }
        .tool-btn.gesture-active { background: var(--warn); color: #000; animation: pulse 2s infinite; }

        /* åº•éƒ¨æ§åˆ¶å€ */
        .controls-area {
            position: absolute; bottom: 0; left: 0; right: 0; z-index: 30;
            background: linear-gradient(to top, rgba(0,0,0,1) 0%, rgba(0,0,0,0.5) 80%, transparent 100%);
            padding-bottom: max(20px, env(safe-area-inset-bottom));
            display: flex; flex-direction: column; gap: 10px;
        }

        /* æ¨¡å¼é¸æ“‡è½‰ç›¤ (Ribbon) */
        .mode-ribbon {
            display: flex; gap: 20px; overflow-x: auto; padding: 10px 50%; 
            scrollbar-width: none; scroll-behavior: smooth;
        }
        .mode-item {
            font-size: 13px; font-weight: 600; color: #888; white-space: nowrap; cursor: pointer;
            transition: 0.2s; text-transform: uppercase; letter-spacing: 1px;
        }
        .mode-item.active { color: var(--warn); transform: scale(1.1); text-shadow: 0 0 10px rgba(255, 215, 0, 0.5); }

        /* å¿«é–€èˆ‡åƒæ•¸ */
        .main-ctrls { display: flex; justify-content: space-around; align-items: center; padding: 0 20px; }
        .shutter {
            width: 70px; height: 70px; border-radius: 50%; border: 4px solid rgba(255,255,255,0.3);
            background: #fff; cursor: pointer; transition: 0.1s;
        }
        .shutter:active { transform: scale(0.9); }
        
        /* è¨Šæ¯æç¤º (Toast) */
        #toast {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            background: rgba(0,0,0,0.85); padding: 15px 25px; border-radius: 12px;
            text-align: center; z-index: 100; display: none; border: 1px solid #333;
        }
        .loader { width: 30px; height: 30px; border: 3px solid #333; border-top: 3px solid var(--accent); border-radius: 50%; animation: spin 1s infinite linear; margin: 0 auto 10px auto; }
        @keyframes spin { 100% { transform: rotate(360deg); } }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(255, 215, 0, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(255, 215, 0, 0); } 100% { box-shadow: 0 0 0 0 rgba(255, 215, 0, 0); } }

        /* ç¿»è­¯çµæœæµ®å±¤ */
        #trans-box {
            position: absolute; bottom: 120px; left: 20px; right: 20px;
            background: rgba(0,0,0,0.8); border: 1px solid var(--accent); padding: 10px;
            border-radius: 8px; color: #fff; font-size: 14px; z-index: 25; display: none;
        }
    </style>
</head>
<body>

    <div class="top-bar">
        <div class="status-badge" id="aiStatus">AI: Standby</div>
        <div class="side-tools">
            <div class="tool-btn" id="btnGesture" onclick="toggleGesture()">âœ‹</div>
            <div class="tool-btn" onclick="toggleCam()">ğŸ“·</div>
            <div class="tool-btn" id="btnTorch" onclick="toggleTorch()">âš¡</div>
        </div>
    </div>

    <div class="viewport">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="cOutput"></canvas>
        <canvas id="cOverlay"></canvas>
        
        <div id="toast">
            <div class="loader"></div>
            <div id="toastMsg">Loading AI Model...</div>
        </div>
        
        <div id="trans-box"></div>
    </div>

    <div class="controls-area">
        <div class="mode-ribbon" id="modeRibbon">
            <div class="mode-item active" onclick="setMode('PRO')">PRO</div>
            <div class="mode-item" onclick="setMode('PORTRAIT')">äººåƒ</div>
            <div class="mode-item" onclick="setMode('SCAN')">æƒæ</div>
            <div class="mode-item" onclick="setMode('DETECT')">è­˜åˆ¥</div>
            <div class="mode-item" onclick="setMode('OCR')">ç¿»è­¯</div>
            <div class="mode-item" onclick="setMode('NIGHT')">å¤œæ™¯</div>
        </div>
        <div class="main-ctrls">
            <div style="width:40px;"></div>
            <div class="shutter" id="shutterBtn" onclick="takeAction()"></div>
            <div class="tool-btn" style="width:40px; height:40px; font-size:12px; border-radius:8px;" onclick="location.reload()">Reset</div>
        </div>
    </div>

<script>
    // --- æ ¸å¿ƒè®Šæ•¸ ---
    const video = document.getElementById('video');
    const cOut = document.getElementById('cOutput');
    const ctxOut = cOut.getContext('2d', { willReadFrequently: true });
    const cOver = document.getElementById('cOverlay');
    const ctxOver = cOver.getContext('2d');
    const toast = document.getElementById('toast');
    const aiStatus = document.getElementById('aiStatus');
    const transBox = document.getElementById('trans-box');
    
    let stream, videoTrack;
    let currentMode = 'PRO';
    let isGestureEnabled = false;
    let isProcessing = false;
    let animationId;
    
    // AI æ¨¡å‹å¯¦ä¾‹
    let models = {
        cocoSsd: null,
        faceMesh: null,
        segmenter: null,
        gestureRecognizer: null,
        tesseractWorker: null
    };
    
    // ç‹€æ…‹æ¨™è¨˜
    let lastGestureTime = 0;
    let scanContour = null; // æƒææ¡†
    let isTorchOn = false;

    // --- åˆå§‹åŒ– ---
    async function init() {
        try {
            stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } } 
            });
            video.srcObject = stream;
            videoTrack = stream.getVideoTracks()[0];
            
            video.onloadedmetadata = () => {
                cOut.width = cOver.width = video.videoWidth;
                cOut.height = cOver.height = video.videoHeight;
                processFrame();
            };
        } catch(e) { alert("Camera Access Error: " + e.message); }
    }

    // --- ä¸»å¾ªç’° (Main Loop) ---
    async function processFrame() {
        if(video.readyState !== 4) { requestAnimationFrame(processFrame); return; }
        
        // 1. åŸºç¤ç¹ªè£½ (å°‡ Video ç•«åˆ° Canvas)
        ctxOut.drawImage(video, 0, 0, cOut.width, cOut.height);
        ctxOver.clearRect(0, 0, cOver.width, cOver.height);

        // 2. æ‰‹å‹¢å¿«é–€åµæ¸¬ (è‹¥é–‹å•Ÿ)
        if(isGestureEnabled) await runGestureLogic();

        // 3. æ ¹æ“šæ¨¡å¼åŸ·è¡Œä¸åŒ AI é‚è¼¯
        if (!isProcessing) {
            try {
                if (currentMode === 'PORTRAIT') await runPortraitMode();
                else if (currentMode === 'DETECT') await runDetectionMode();
                else if (currentMode === 'SCAN') runScannerMode(); // OpenCV æ˜¯åŒæ­¥çš„
                // OCR èˆ‡ Night Mode æ˜¯é»æ“Šå¾Œè§¸ç™¼ï¼Œä¸è·‘å³æ™‚è¿´åœˆ
            } catch(e) { console.error(e); }
        }

        animationId = requestAnimationFrame(processFrame);
    }

    // --- æ¨¡å¼åˆ‡æ›é‚è¼¯ ---
    window.setMode = async function(mode) {
        if(currentMode === mode) return;
        currentMode = mode;
        
        // UI æ›´æ–°
        document.querySelectorAll('.mode-item').forEach(el => {
            el.classList.toggle('active', el.innerText === getModeName(mode));
        });
        transBox.style.display = 'none';
        
        // æ¨¡å‹è¼‰å…¥é‚è¼¯
        showToast("è¼‰å…¥åŠŸèƒ½ä¸­...", true);
        isProcessing = true; // æš«åœ Render loop é‚è¼¯

        try {
            if(mode === 'DETECT' && !models.cocoSsd) {
                aiStatus.innerText = "AI: Loading Coco...";
                models.cocoSsd = await cocoSsd.load();
            }
            if(mode === 'PORTRAIT' && !models.segmenter) {
                aiStatus.innerText = "AI: Loading Segmenter...";
                const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm");
                models.segmenter = await ImageSegmenter.createFromOptions(vision, {
                    baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/image_segmenter/deeplab_v3/float32/1/deeplab_v3.tflite" },
                    outputCategoryMask: true,
                    runningMode: "VIDEO"
                });
            }
            if(mode === 'OCR' && !models.tesseractWorker) {
                 aiStatus.innerText = "AI: Loading OCR...";
                 // Tesseract æœƒåœ¨é¦–æ¬¡åŸ·è¡Œæ™‚è¼‰å…¥
            }
        } catch(e) {
            alert("æ¨¡å‹è¼‰å…¥å¤±æ•—: " + e.message);
            setMode('PRO');
        } finally {
            isProcessing = false;
            hideToast();
            aiStatus.innerText = `AI: ${mode} Ready`;
        }
    }

    function getModeName(m) {
        const map = { 'PRO':'PRO', 'PORTRAIT':'äººåƒ', 'SCAN':'æƒæ', 'DETECT':'è­˜åˆ¥', 'OCR':'ç¿»è­¯', 'NIGHT':'å¤œæ™¯' };
        return map[m];
    }

    // --- 1. äººåƒæ¨¡å¼ (èƒŒæ™¯è™›åŒ–) ---
    async function runPortraitMode() {
        if (!models.segmenter) return;
        
        // å–å¾—åˆ†å‰²çµæœ
        const startTimeMs = performance.now();
        const result = models.segmenter.segmentForVideo(video, startTimeMs);
        
        if (result.categoryMask) {
            // 1. ç¹ªè£½åŸå§‹å½±åƒ
            ctxOut.drawImage(video, 0, 0);
            
            // 2. æº–å‚™é®ç½©èˆ‡æ¨¡ç³ŠèƒŒæ™¯
            const width = video.videoWidth;
            const height = video.videoHeight;
            const imageData = ctxOut.getImageData(0, 0, width, height);
            const mask = result.categoryMask.getAsUint8Array();
            
            // ç‚ºäº†æ•ˆèƒ½ï¼Œæˆ‘å€‘ç”¨ç°¡å–®çš„åƒç´ æ“ä½œæ¨¡æ“¬é®ç½©
            // ç†æƒ³åšæ³•æ˜¯: ç”¨ Canvas æ¨¡ç³Šæ•´å¼µåœ– -> ç”¨ Mask è£åˆ‡å‡ºäººåƒ -> è“‹ä¸Šå»
            
            // ç°¡æ˜“ç‰ˆï¼šç›´æ¥ç”¢ç”Ÿä¸€å€‹ Offscreen Canvas åšæ¨¡ç³Š
            const offCvs = document.createElement('canvas');
            offCvs.width = width; offCvs.height = height;
            const offCtx = offCvs.getContext('2d');
            offCtx.filter = 'blur(10px)'; // èƒŒæ™¯æ¨¡ç³Šç¨‹åº¦
            offCtx.drawImage(video, 0, 0);
            
            const blurData = offCtx.getImageData(0, 0, width, height).data;
            const rawData = imageData.data;
            
            // æ··åˆåƒç´  (Mask=0æ˜¯èƒŒæ™¯ï¼ŒMask=255æ˜¯äºº)
            // MediaPipe DeepLab V3 è¼¸å‡ºå¯èƒ½æ˜¯ class index
            // é€™è£¡ç°¡åŒ–ï¼šåªè¦ä¸æ˜¯äºº(class 15) å°±æ¨¡ç³Š (DeepLab æ¯”è¼ƒè¤‡é›œï¼Œé€™é‚Šå‡è¨­ mask å€¼æœ‰å€åˆ¥)
            // å› ç‚º Web æ•ˆèƒ½ï¼Œæˆ‘å€‘åªåšç°¡å–®åˆ¤æ–·
            for (let i = 0; i < mask.length; ++i) {
                // å¦‚æœæ˜¯äºº(å€¼å¤§)ï¼Œä¿ç•™åŸåœ–ï¼›å¦å‰‡ä½¿ç”¨æ¨¡ç³Šåœ–
                // é€™è£¡ mask å€¼é€šå¸¸æ˜¯ 0-255 çš„ confidence
                // è‹¥ä½¿ç”¨ categoryMaskï¼Œå€¼æ˜¯é¡åˆ¥ IDã€‚DeepLab äººé€šå¸¸æ˜¯ 15ã€‚
                // ç‚ºäº†é€šç”¨æ€§ï¼Œæˆ‘å€‘å‡è¨­ segmenter æœ‰æ­£ç¢ºè¨­å®šã€‚
                // é€™è£¡ä½¿ç”¨ç°¡å–®çš„é€æ˜åº¦æ··åˆï¼Œå¯¦éš›éœ€æ ¹æ“šæ¨¡å‹èª¿æ•´
                
                // è¨»ï¼šé€™æ­¥åœ¨ JS è¿´åœˆåš 720p å½±åƒæœƒå¾ˆæ…¢ (LAG)ã€‚
                // ç‚ºäº†æµæš¢åº¦ï¼Œæˆ‘å€‘åªå° Canvas æ‡‰ç”¨ globalCompositeOperation
            }
            
            // â˜… é«˜æ•ˆåšæ³• â˜…
            // 1. ç•«æ¨¡ç³ŠèƒŒæ™¯
            ctxOut.filter = 'blur(8px)';
            ctxOut.drawImage(video, 0, 0);
            ctxOut.filter = 'none';
            
            // 2. å°‡é®ç½©è½‰ç‚ºåœ–åƒä¸¦è£åˆ‡äººåƒ
            // é€™é‚Šéœ€è¦å°‡ mask array è½‰ç‚º ImageData ä¸¦ç•«ä¸Šå»ï¼Œæœƒæ¯”è¼ƒè¤‡é›œ
            // ç‚ºäº†ç¤ºç¯„ä¸”ä¿æŒå–®æª”å¯é‹è¡Œï¼Œæˆ‘å€‘æš«æ™‚åªåšã€Œåµæ¸¬åˆ°äººå°±ç•«å€‹æ¡†ã€æˆ–è€…çœç•¥å³æ™‚è™›åŒ–é è¦½
            // æ”¹ç‚ºï¼šæ‹ä¸‹ç…§ç‰‡æ™‚æ‰è™•ç†è™›åŒ–ï¼Œé è¦½åªé¡¯ç¤ºã€Œäººåƒæ¨¡å¼å°±ç·’ã€
            
            ctxOver.fillStyle = 'rgba(255, 255, 255, 0.5)';
            ctxOver.font = '20px Arial';
            ctxOver.fillText("Background Blur Active (Preview Low Qual)", 20, 30);
        }
    }

    // --- 2. è¬ç‰©è­˜åˆ¥ (Object Detection) ---
    async function runDetectionMode() {
        if (!models.cocoSsd) return;
        const predictions = await models.cocoSsd.detect(video);
        
        ctxOver.font = '16px sans-serif';
        ctxOver.textBaseline = 'top';
        
        predictions.forEach(prediction => {
            const x = prediction.bbox[0];
            const y = prediction.bbox[1];
            const w = prediction.bbox[2];
            const h = prediction.bbox[3];
            
            // ç•«æ¡†
            ctxOver.strokeStyle = '#00FFFF';
            ctxOver.lineWidth = 2;
            ctxOver.strokeRect(x, y, w, h);
            
            // ç•«æ¨™ç±¤èƒŒæ™¯
            const text = `${prediction.class} ${Math.round(prediction.score * 100)}%`;
            const textWidth = ctxOver.measureText(text).width;
            ctxOver.fillStyle = '#00FFFF';
            ctxOver.fillRect(x, y, textWidth + 4, 20);
            
            // ç•«æ–‡å­—
            ctxOver.fillStyle = '#000000';
            ctxOver.fillText(text, x + 2, y + 2);
        });
    }

    // --- 3. æ–‡ä»¶æƒæ (OpenCV) ---
    function runScannerMode() {
        if (typeof cv === 'undefined') return;
        
        let src = cv.imread(cOut);
        let gray = new cv.Mat();
        
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
        cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
        cv.Canny(gray, gray, 75, 200);
        
        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(gray, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        
        let maxArea = 0;
        let bestContour = null;
        
        for (let i = 0; i < contours.size(); ++i) {
            let cnt = contours.get(i);
            let area = cv.contourArea(cnt);
            if (area > 5000) { // å¿½ç•¥å¤ªå°çš„
                let peri = cv.arcLength(cnt, true);
                let approx = new cv.Mat();
                cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
                if (approx.rows === 4 && area > maxArea) {
                    maxArea = area;
                    bestContour = approx;
                } else {
                    approx.delete();
                }
            }
        }

        if (bestContour) {
            // ç¹ªè£½å››é‚Šå½¢
            ctxOver.strokeStyle = '#00ff00';
            ctxOver.lineWidth = 4;
            ctxOver.beginPath();
            
            let pts = [];
            for(let i=0; i<4; i++) {
                pts.push({x: bestContour.data32S[i*2], y: bestContour.data32S[i*2+1]});
            }
            
            ctxOver.moveTo(pts[0].x, pts[0].y);
            ctxOver.lineTo(pts[1].x, pts[1].y);
            ctxOver.lineTo(pts[2].x, pts[2].y);
            ctxOver.lineTo(pts[3].x, pts[3].y);
            ctxOver.closePath();
            ctxOver.stroke();
            
            scanContour = bestContour; // å­˜èµ·ä¾†æ‹ç…§ç”¨
        } else {
            scanContour = null;
        }

        src.delete(); gray.delete(); contours.delete(); hierarchy.delete();
    }

    // --- 4. æ‰‹å‹¢å¿«é–€ (Gesture) ---
    async function toggleGesture() {
        if(!isGestureEnabled) {
            if(!models.gestureRecognizer) {
                showToast("ä¸‹è¼‰æ‰‹å‹¢æ¨¡å‹...");
                const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm");
                models.gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                    baseOptions: { modelAssetPath: "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task" },
                    runningMode: "VIDEO"
                });
                hideToast();
            }
            isGestureEnabled = true;
            document.getElementById('btnGesture').classList.add('gesture-active');
            aiStatus.innerText = "AI: Gesture Ready (Show âœŒï¸ or âœ‹)";
        } else {
            isGestureEnabled = false;
            document.getElementById('btnGesture').classList.remove('gesture-active');
        }
    }

    async function runGestureLogic() {
        if(!models.gestureRecognizer) return;
        const now = Date.now();
        if (now - lastGestureTime < 2000) return; // å†·å»æ™‚é–“

        const results = models.gestureRecognizer.recognizeForVideo(video, now);
        if (results.gestures.length > 0) {
            const gesture = results.gestures[0][0];
            const name = gesture.categoryName;
            const score = gesture.score;

            if (score > 0.6 && (name === "Victory" || name === "Open_Palm")) {
                console.log("Gesture Detected:", name);
                lastGestureTime = now;
                triggerCountdown(3);
            }
        }
    }

    // --- 5. è§¸ç™¼å‹•ä½œ (æ‹ç…§/è­˜åˆ¥/æƒæ) ---
    async function takeAction() {
        showToast("Processing...");
        
        // æš«åœç•«é¢
        video.pause();
        
        if (currentMode === 'OCR') {
            await doOCR();
        } else if (currentMode === 'SCAN') {
            await doDocScan();
        } else if (currentMode === 'NIGHT') {
            await doNightMode();
        } else if (currentMode === 'PORTRAIT') {
             // å¯¦éš›æ‡‰ç”¨éœ€åœ¨æ­¤è™•åšç²¾ç´°çš„ Segmentation + Blur
             saveCanvas("AI_Portrait");
        } else {
             // ä¸€èˆ¬æ‹ç…§ & ç‰©ä»¶è­˜åˆ¥æˆªåœ–
             saveCanvas("AI_Photo");
        }
        
        video.play();
        hideToast();
    }

    // --- åŠŸèƒ½å¯¦ä½œ: OCR & ç¿»è­¯ ---
    async function doOCR() {
        aiStatus.innerText = "AI: Reading Text...";
        
        // ä½¿ç”¨ Tesseract.js
        const result = await Tesseract.recognize(cOut, 'eng+chi_tra', {
            logger: m => { if(m.status === 'recognizing text') showToast(`OCR: ${(m.progress*100).toFixed(0)}%`) }
        });
        
        const text = result.data.text.trim();
        if(text.length > 0) {
            // æ¨¡æ“¬ç¿»è­¯ (å› ç‚º Google Translate API è¦éŒ¢)
            // é€™è£¡æˆ‘å€‘ç›´æ¥é¡¯ç¤ºåŸæ–‡ï¼Œä¸¦æä¾›æŒ‰éˆ•å» Google æŸ¥
            transBox.style.display = 'block';
            transBox.innerHTML = `
                <div style="margin-bottom:5px; font-weight:bold; color:var(--accent)">è­˜åˆ¥æ–‡å­—:</div>
                <div style="max-height:60px; overflow-y:auto; margin-bottom:5px;">${text}</div>
                <hr style="border-color:#555">
                <div style="font-size:12px; color:#aaa;">(æ¨¡æ“¬ç¿»è­¯åŠŸèƒ½) è‡ªå‹•åµæ¸¬èªè¨€ä¸¦ç¿»è­¯...</div>
                <div style="color:#fff; margin-top:5px;">${text} <span style="color:var(--warn)">(å·²ç¿»è­¯)</span></div>
                <a href="https://translate.google.com/?text=${encodeURIComponent(text)}" target="_blank" style="display:block; margin-top:10px; color:var(--accent); text-align:center;">åœ¨ Google ç¿»è­¯ä¸­é–‹å•Ÿ</a>
            `;
        } else {
            showToast("æœªåµæ¸¬åˆ°æ–‡å­—");
        }
    }

    // --- åŠŸèƒ½å¯¦ä½œ: æ–‡ä»¶æƒææ ¡æ­£ ---
    async function doDocScan() {
        if (!scanContour) {
            showToast("æœªåµæ¸¬åˆ°æ–‡ä»¶é‚Šç·£");
            return;
        }
        
        let src = cv.imread(cOut);
        // å»ºç«‹é€è¦–è®Šæ›çš„å››å€‹é»
        // é€™è£¡ç°¡åŒ–ï¼šå‡è¨­ scanContour é †åºæ­£ç¢º (å¯¦éš›éœ€è¦æ’åºå·¦ä¸Š/å³ä¸Š/å³ä¸‹/å·¦ä¸‹)
        // ç‚ºäº†å±•ç¤ºæ•ˆæœï¼Œæˆ‘å€‘å…ˆç›´æ¥å­˜åŸåœ– + è£åˆ‡æ¡†
        // çœŸæ­£æ ¡æ­£éœ€è¦ cv.getPerspectiveTransform + cv.warpPerspective
        
        // é€™è£¡åšä¸€å€‹ç°¡å–®çš„ç¤ºæ„ï¼šåªç•«å‡ºç¶ è‰²æ¡†ä¸¦å„²å­˜
        saveCanvas("Doc_Scan");
        
        // è‹¥è¦å¯¦ä½œ warpPerspectiveï¼Œéœ€è¦å° scanContour çš„é»é€²è¡Œæ’åºï¼Œç„¶å¾Œå®šç¾©ç›®æ¨™å¯¬é«˜
        src.delete();
    }

    // --- åŠŸèƒ½å¯¦ä½œ: å¤œæ™¯æ¨¡å¼ (æ¨¡æ“¬) ---
    async function doNightMode() {
        // æ¨¡æ“¬ï¼šç–ŠåŠ å¤šå¼µåœ– + æé«˜äº®åº¦ + é™å™ª
        // å› ç‚ºç„¡æ³•æ§åˆ¶å¿«é–€ï¼Œæˆ‘å€‘ç”¨ Gain (Brightness) æ¨¡æ“¬
        
        const ctx = cOut.getContext('2d');
        ctx.filter = 'brightness(1.5) contrast(1.1) saturate(1.2)';
        ctx.drawImage(video, 0, 0);
        ctx.filter = 'none'; // é‡ç½®
        
        // ç°¡å–®é™å™ª
        // åœ¨ Web ä¸Šåš Neural Denoise å¤ªæ…¢ï¼Œæˆ‘å€‘ç”¨ OpenCV çš„æ¨¡ç³Šä»£æ›¿è‰²åº¦é›œè¨Šå»é™¤
        // é€™è£¡ç›´æ¥è¼¸å‡ºäº®åº¦å¢å¼·ç‰ˆ
        saveCanvas("AI_NightSight");
    }

    // --- è¼”åŠ©åŠŸèƒ½ ---
    function triggerCountdown(seconds) {
        let n = seconds;
        const timer = setInterval(() => {
            showToast(`ğŸ“¸ ${n}...`);
            n--;
            if (n < 0) {
                clearInterval(timer);
                takeAction();
            }
        }, 1000);
    }

    function saveCanvas(prefix) {
        const link = document.createElement('a');
        link.download = `${prefix}_${Date.now()}.jpg`;
        link.href = cOut.toDataURL('image/jpeg', 0.95);
        link.click();
        showToast("å·²å„²å­˜!");
    }

    function showToast(msg, persist=false) {
        document.getElementById('toastMsg').innerText = msg;
        toast.style.display = 'block';
        if(!persist) setTimeout(hideToast, 2000);
    }
    
    function hideToast() {
        toast.style.display = 'none';
    }

    function toggleTorch() {
        isTorchOn = !isTorchOn;
        if(videoTrack) {
            videoTrack.applyConstraints({ advanced: [{ torch: isTorchOn }] }).catch(e => console.log(e));
        }
        document.getElementById('btnTorch').classList.toggle('active', isTorchOn);
    }

    function toggleCam() {
        // ç°¡æ˜“åˆ‡æ›å‰å¾Œé¡é ­
        // å¯¦éš›éœ€é‡æ–° init stream
        alert("åˆ‡æ›é¡é ­åŠŸèƒ½éœ€é‡æ–°è«‹æ±‚ä¸²æµï¼Œç‚ºä¿æŒå–®æª”ç°¡æ½”æš«æœªå¯¦ä½œ");
    }

    function onOpenCvReady() {
        console.log("OpenCV Ready");
    }

    // å•Ÿå‹•
    init();

</script>
</body>
</html>


